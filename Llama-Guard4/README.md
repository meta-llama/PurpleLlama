# Meta Llama Guard 4

Llama Guard 4 is a model that provides input and output guardrails for LLM deployments, based on MLCommons policy.

# Quick Start

Since Llama Guard 4 is a fine-tuned Llama 4 model (see our [model card](12B/MODEL_CARD.md) for more information), the same quick start steps outlined in the [README file](https://github.com/meta-llama/llama-models/blob/main/README.md) for Llama 4 apply here.

# Issues

Please report any software bug, or other problems with the models, through one of the following channels:

- Reporting issues with the Llama Guard model:
  [github.com/meta-llama/PurpleLlama](https://github.com/meta-llama/PurpleLlama)
- Reporting issues with Llama in general:
  [github.com/meta-llama/llama-models](https://github.com/meta-llama/llama-models)
- Reporting risky content generated by the model:
  [developers.facebook.com/llama_output_feedback](https://developers.facebook.com/llama_output_feedback)
- Reporting bugs and security concerns:
  [facebook.com/whitehat/info](https://facebook.com/whitehat/info)

# License

Our model and weights are licensed for both researchers and commercial entities, upholding the principles of openness. Our mission is to empower individuals and industry through this opportunity, while fostering an environment of discovery and ethical AI advancements.

See our [LICENSE](12B/LICENSE) file and our accompanying [Acceptable Use Policy](12B/USE_POLICY.md).
