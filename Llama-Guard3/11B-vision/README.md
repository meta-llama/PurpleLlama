# Meta Llama Guard 3-11B-vision

Llama Guard 3-11B-vision is a model that provides input and output guardrails for LLM deployments, based on MLCommons policy. It is capable of image reasoning with mixed text/image inputs.

# Download

Please see the [Llama CLI Reference](https://github.com/meta-llama/llama-stack/blob/main/docs/cli_reference.md#step-1-get-the-models) for downloading this model.

# Quick Start

Since Llama Guard 3 is a fine-tuned Llama 3.1 model (see our
[model card](MODEL_CARD.md) for more information), the same quick start steps
outlined in our
[README file](https://github.com/meta-llama/llama-models/blob/main/README.md) for
Llama3 apply here.

In addition to that, we added examples using Llama Guard 3 in the
[Llama recipes repository](https://github.com/facebookresearch/llama-recipes).

# Issues

Please report any software bug, or other problems with the models through one of
the following means:

- Reporting issues with the Llama Guard model:
  [github.com/meta-llama/PurpleLlama](https://github.com/meta-llama/PurpleLlama)
- Reporting issues with Llama in general:
  [github.com/meta-llama/llama-models](https://github.com/meta-llama/llama-models)
- Reporting risky content generated by the model:
  [developers.facebook.com/llama_output_feedback](https://developers.facebook.com/llama_output_feedback)
- Reporting bugs and security concerns:
  [facebook.com/whitehat/info](https://facebook.com/whitehat/info)

# License

Our model and weights are licensed for both researchers and commercial entities,
upholding the principles of openness. Our mission is to empower individuals, and
industry through this opportunity, while fostering an environment of discovery
and ethical AI advancements.

The same license as Llama 3.1 applies: see the [LICENSE](LICENSE) file, as well
as our accompanying [Acceptable Use Policy](USE_POLICY.md).

# Citation
```
@misc{chi2024llamaguard3vision,
      title={Llama Guard 3 Vision: Safeguarding Human-AI Image Understanding Conversations},
      author={Jianfeng Chi and Ujjwal Karn and Hongyuan Zhan and Eric Smith and Javier Rando and Yiming Zhang and Kate Plawiak and Zacharie Delpierre Coudert and Kartikeya Upasani and Mahesh Pasupuleti},
      year={2024},
      eprint={2411.10414},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2411.10414},
}
```

# References

[Research Paper](https://ai.facebook.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/)
