# Copyright (c) Meta Platforms, Inc. and affiliates.
#
# This source code is licensed under the MIT license found in the
# LICENSE file in the root directory of this source tree.

# pyre-strict

from __future__ import annotations

import logging
from typing import List

from .llms.anthropic import ANTHROPIC
from .llms.googlegenai import GOOGLEGENAI

from .llms.llm_base import (
    DEFAULT_MAX_TOKENS,
    DEFAULT_TEMPERATURE,
    DEFAULT_TOP_P,
    LLM,
    LLMConfig,
    MAX_RETRY_TIMEOUT,
    NUM_LLM_RETRIES,
    RetriesExceededException,
    UnretriableQueryException,
)
from .llms.openai import OPENAI
from .llms.together import TOGETHER

LOG: logging.Logger = logging.getLogger(__name__)


SPECIFICATION_FORMAT: str = "<PROVIDER>::<MODEL>(::<API KEY>)?"
EXAMPLE_SPECIFICATION: str = "OPENAI::gpt-3.5-turbo::<YOUR API KEY>"


def create(
    identifier: str,
    max_tokens: int = DEFAULT_MAX_TOKENS,
    cot_end_tokens: List[str] | None = None,
) -> LLM:
    """
    Takes a string of the format <SPECIFICATION_FORMAT> and generates LLM instance.
    See <EXAMPLE_SPECIFICATION> for example.
    """
    api_key: str | None = None
    split = identifier.split("::")
    if len(split) == 2:
        provider, name = split
    elif len(split) == 3:
        provider, name, api_key = split
    else:
        raise ValueError(f"Invalid identifier: {identifier}")

    if api_key is None:
        raise ValueError(f"No API key provided for {provider}: {name}")

    config = LLMConfig(
        model=name,
        api_key=api_key,
        max_tokens=max_tokens,
        cot_end_tokens=cot_end_tokens,
    )

    if provider == "OPENAI":
        return OPENAI(config)
    if provider == "TOGETHER":
        return TOGETHER(config)
    if provider == "ANTHROPIC":
        return ANTHROPIC(config)
    if provider == "GOOGLEGENAI":
        return GOOGLEGENAI(config)

    raise ValueError(f"Unknown provider: {provider}")
